{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Authors: Rafael Dousse, Eva Ray, Massimo Stefani",
   "id": "5aa2e6a5b3b11df2"
  },
  {
   "cell_type": "markdown",
   "id": "ad0d40d6",
   "metadata": {},
   "source": [
    "# Exercice 3 - Review questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e556a9d",
   "metadata": {},
   "source": [
    "**a) Assuming an univariate input *x*, what is the complexity at inference time of a Bayesian classifier based on histogram computation of the likelihood ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fb7ef",
   "metadata": {},
   "source": [
    "The complexity is O(K) where K is the number of classes.\n",
    "\n",
    "For a univariate feature (D = 1) a histogram-based likelihood is a constant-time lookup per class (find the bin → O(1)), then multiply by the prior and compare. Doing that for all K classes gives O(K·1) = O(K). (If K and D are treated as constants and small, authors sometimes write this as ~O(1).) (Slide 26 from the week 3 lecture.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99632770",
   "metadata": {},
   "source": [
    "**b) Bayesian models are said to be generative as they can be used to generate new samples. Taking the implementation of the exercise 1.a, explain the steps to generate new samples using the system you have put into place.**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab64b2",
   "metadata": {},
   "source": [
    "The procedure is as follows:\n",
    "1. Draw a class C according to the prior distribution P(C).\n",
    "2. Draw a sample x from the likelihood distribution P(x|C) corresponding to the selected class C. In our case, we can use the histogram to determine the bin probabilities and sample accordingly.\n",
    "3. Repeat the above steps to generate as many samples as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f611fe",
   "metadata": {},
   "source": [
    "***Optional*: Provide an implementation in a function generateSample(priors, histValues, edgeValues, n)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14aba0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generateSample(priors, histValues, edgeValues, n):\n",
    "    samples = []\n",
    "    classes = [0, 1]\n",
    "    for _ in range(n):\n",
    "        # Step 1: Draw a class C according to the prior distribution P(C).\n",
    "        C = np.random.choice(classes, p=priors)\n",
    "        # Step 2: Draw a sample x from the likelihood distribution P(x|C).\n",
    "        hist = histValues[C]\n",
    "        edges = edgeValues[C]\n",
    "        # Choose a bin according to the histogram probabilities\n",
    "        bin = np.random.choice(len(hist), p=hist/hist.sum())\n",
    "        # Uniformly sample within the bin\n",
    "        x = np.random.uniform(edges[bin], edges[bin + 1])\n",
    "        samples.append((x, C))\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c4f6b",
   "metadata": {},
   "source": [
    "**c) What is the minimum overall accuracy of a 2-class system relying only on priors and that is built on a training set that includes 5 times more samples in class A than in class B?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb03365",
   "metadata": {},
   "source": "We have P(B) = 5 * P(A) and P(A) + P(B) = 1, so P(A) = 1/6 and P(B) = 5/6. Since we only rely on priors, we will always predict the most probable class, which is class B. Therefore, the minimum overall accuracy is P(B) = 5/6."
  },
  {
   "cell_type": "markdown",
   "id": "58450ff6",
   "metadata": {},
   "source": [
    "**d) Let’s look back at the PW02 exercise 3 of last week. We have built a knn classification systems for images of digits on the MNIST database.**\n",
    "\n",
    "**How would you build a Bayesian classification for the same task ? Comment on the prior probabilities and on the likelihood estimators. More specifically, what kind of likelihood estimator could we use in this case ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf1500",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca9715",
   "metadata": {},
   "source": [
    "***Optional:* implement it and report performance !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de72736",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812b46f",
   "metadata": {},
   "source": [
    "**e) Read [europe-border-control-ai-lie-detector](https://theintercept.com/2019/07/26/europe-border-control-ai-lie-detector/). The described system is \"a virtual policeman designed to strengthen European borders\". It can be seen as a 2-class problem, either you are a suspicious traveler or you are not. If you are declared as suspicious by the system, you are routed to a human border agent who analyses your case in a more careful way.**\n",
    "\n",
    "1. What kind of errors can the system make ? Explain them in your own words.\n",
    "2. Is one error more critical than the other ? Explain why.\n",
    "3. According to the previous points, which metric would you recommend to tune your MLsystem ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf1760",
   "metadata": {},
   "source": [
    "1. The system can make two types of errors: false positives (FP) and false negatives (FN).\n",
    "    - FP occurs when a non-suspicious traveler is incorrectly classified as suspicious, leading to unnecessary scrutiny and potential delays.\n",
    "    - FN occurs when a suspicious traveler is incorrectly classified as non-suspicious, allowing them to pass through the border without additional checks.\n",
    "2. A FN is more critical than a FP because it can lead to security risks, such as allowing individuals who may pose a threat to enter the country without proper screening. FPs only cause inconvenience to innocent travelers, which is less severe than the potential consequences of a FN.\n",
    "3. Our goal is to minimize the number of FNs (while keeping FPs at a reasonable level). Thus, we should focus on recall. A high recall ensures that most suspicious travelers are correctly identified, even if it means accepting a higher number of FPs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a1f73-c0f7-4707-9551-c71bfa379960",
   "metadata": {},
   "source": [
    "**f) When a deep learning architecture is trained using an unbalanced training set, we usually observe a problem of bias, i.e. the system favors one class over another one. Using the Bayes equation, explain what is the origin of the problem.**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Remember that the Bayes equation is given by: P(C|x) = P(x|C) * P(C) / P(x)\n",
    "\n",
    "When the training set is unbalanced, the majority class has a higher prior probability P(C) than the minority class. As a result, the model tends to predict the majority class more often, since P(C) appears in the numerator of Bayes’ equation. This bias occurs because the model learns to associate features more strongly with the majority class due to its higher frequency in the training data."
   ],
   "id": "db822b30b99cfd4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
