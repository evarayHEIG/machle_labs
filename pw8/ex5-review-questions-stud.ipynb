{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### authors: Rafael Dousse, Eva Ray, Massimo Stefani",
   "id": "9b42d210d28b6030"
  },
  {
   "cell_type": "markdown",
   "id": "d07f854c",
   "metadata": {},
   "source": [
    "# PW8 - Exercise 5 - Review Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f9abb1",
   "metadata": {},
   "source": [
    "## a) Re-explain in your own words the steps of the K-Means algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871d20c",
   "metadata": {},
   "source": [
    "The goal of the K-Means algorithm is to partition a dataset into K distinct clusters based on feature similarity. The steps are as follows:\n",
    "1. **Initialization**: Randomly select K initial centroids from the dataset. These centroids represent the initial center points of the clusters.\n",
    "2. **Assignment**: For each data point in the dataset, calculate the distance to each centroid and assign the data point to the cluster of the nearest centroid. This step groups the data points based on their proximity to the centroids.\n",
    "3. **Update**: After all data points have been assigned to clusters, recalculate the centroids by taking the mean of all data points assigned to each cluster. This step updates the position of the centroids to better represent the clusters.\n",
    "4. **Repeat**: Repeat the Assignment and Update steps until convergence, which occurs when the centroids no longer change significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8288da",
   "metadata": {},
   "source": [
    "## b) Are we guaranteed to observe a decreasing distortion J from one epoch to the other in the K-Means ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ed82c",
   "metadata": {},
   "source": [
    "Yes, we are guaranteed to observe a non-increasing distortion J from one epoch to the other in the K-Means algorithm (slide 41). This is because, during the Assignment step, each data point is assigned to the nearest centroid, which minimizes the distance between the data points and their assigned centroids. In the Update step, the centroids are recalculated as the mean of the assigned data points, which also minimizes the overall distortion. Therefore, each iteration of the K-Means algorithm either reduces or maintains the distortion J, leading to convergence.\n",
    "\n",
    "However, it is interesting to note that while the distortion J is guaranteed to decrease, the K-Means algorithm can converge to a local minimum rather than the global minimum. This means that the final clustering result may depend on the initial placement of the centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d614f",
   "metadata": {},
   "source": [
    "## c) For two different initial values of the centroids in the K-Means, can we get different end values of the distortion J ? Argument your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a47dd4",
   "metadata": {},
   "source": "Yes, for two different initial values of the centroids in the K-Means algorithm, we can indeed get different end values of the distortion J. This is because the K-Means algorithm is sensitive to the initial placement of the centroids. Depending on where the centroids are initialized, the algorithm may converge to different local minima of the distortion function."
  },
  {
   "cell_type": "markdown",
   "id": "2f223bb3",
   "metadata": {},
   "source": [
    "## d) Can the K-Means be used as a compression algorithm ? Compute the compression ratio for a setting with 256 centroids and an input space at two dimensions ($x_1$, $x_2$) encoded in float32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7ae52",
   "metadata": {},
   "source": [
    "Yes, K-Means can be used as a compression algorithm. The idea is to encode the input space in a smaller representation by replacing each data point with the index of the nearest centroid. This reduces the amount of data needed to represent the original dataset. This technique can be used, for example, to reduce bandwidth in image transmission or voice compression, as seen in the course.\n",
    "\n",
    "The compression ratio is calculated as follows: Compression Ratio = (Original data Size) / (Compressed data Size). Let's say that the number of data points is N.\n",
    "- Original data size: Each data point has 2 dimensions (x1, x2), each encoded in float32 (4 bytes). Therefore, the original data size is: Original data Size = N * 2 * 4 bytes = 8N bytes.\n",
    "- Compressed data size: Each data point is represented by the index of the nearest centroid. With 256 centroids, we need 1 byte (8 bits) to represent the index of each centroid. Therefore, the compressed data size is: Compressed data Size = N * 1 byte = N bytes.\n",
    "- Compression Ratio = (8N bytes) / (N bytes) = 8.\n",
    "\n",
    "Thus, the compression ratio for a setting with 256 centroids and an input space at two dimensions encoded in float32 is 8.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34dab83",
   "metadata": {},
   "source": [
    "## e) What is the use of the elbow method ? Explain it in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8648e",
   "metadata": {},
   "source": [
    "One of the challenges in using the K-Means algorithm is determining the optimal number of clusters K to use. The elbow method is a technique that helps to identify the appropriate value of K by analyzing the distortion J as a function of K. The idea is to run the K-Means algorithm for a range of K values and compute the distortion J for each K. The distortion is then plotted in a graph, with K on the x-axis and distortion J on the y-axis.\n",
    "\n",
    "As K increases, the distortion J typically decreases because more clusters help better describe the data. However, there is a point where the rate of decrease in distortion starts to slow down significantly, forming an \"elbow\" shape in the graph. This elbow point indicates that adding more clusters beyond this point does not significantly improve the clustering quality. Therefore, the elbow method suggests selecting the value of K at this elbow point as the optimal number of clusters for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0206d1d",
   "metadata": {},
   "source": [
    "## f) Give an example where we would know in advance the number of clusters we want to discover with a clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948c3ba",
   "metadata": {},
   "source": [
    "It is possible to choose an \"a priori\" K, due to application purposes.\n",
    "\n",
    "For example, let's assume that i have a dataset containing the heights and weights of 5000 people. My goal is to determine 5 clusters representing the t-shirt sized categories: XS, S, M, L, XL. In this case, I know in advance that I want to discover 5 clusters corresponding to these t-shirt sizes. Therefore, I can set K=5 in the K-Means algorithm to group the data points into these predefined categories based on their height and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b04b3b",
   "metadata": {},
   "source": [
    "## g) It is possible to compute the distortion $J_k$ for a given centroid k. If we observe that the distortion $J_k$ for centroid k is really bigger than the other distortions and that the number of points $N_k$ associated to this centroid is also bigger than for the other centroids, what can we say about the dataset and cluster k of points ? Could you suggest a strategy to make things better ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c118765",
   "metadata": {},
   "source": [
    "This situation suggests that cluster k is likely too large and may be encompassing multiple sub-clusters within it. The high distortion $J_k$ indicates that the points assigned to this centroid are spread out and not well-represented by the centroid, while the large number of points $N_k$ suggests that this cluster is capturing a significant portion of the dataset.\n",
    "\n",
    "To make things better, here are some strategies ideas:\n",
    "- **Increase the number of clusters (K)**: By increasing K, we can allow the algorithm to create more centroids, which may help to better capture the underlying structure of the data. Here, we can imagine that the cluster k could be split into two or more smaller clusters, each with its own centroid.\n",
    "- **Reinitialize centroids**: As discussed before, the initial placement of centroids can lead to suboptimal clustering. We can consider running the K-Means algorithm multiple times with different initializations and selecting the clustering that gives the lowest distortion.\n",
    "- **Use a different clustering algorithm**: If K-Means is not effectively capturing the structure of the data, we might consider using other clustering algorithms. K-means is a distortion-based algorithm, which is not suited for datasets that rely more on connectivity, which could be the case here. Algorithms like DBSCAN or hierarchical clustering might be more appropriate in such cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
